{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58866218",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FILENAME = 'car_ped_stops_2024-03-16T20_22_24.zip'\n",
    "#DATA_DIR = os.path.dirname(deo_backend.__file__)\n",
    "\n",
    "# This handles replacing individual year files with a separate backup but you have to update the Run object.\n",
    "\n",
    "DATA_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import click\n",
    "import httpx\n",
    "import sqlite3\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime, date, timedelta\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "MOST_RECENT_QUARTER_START_DT = \"2023-10-01\"\n",
    "MOST_RECENT_COMPLETED_YEAR = (datetime.now() - timedelta(days=365)).year\n",
    "DIST_FROM_HIN_THRESHOLD = 0.0001\n",
    "\"\"\"\n",
    "--- This shows that 0.0001 is between 8.54427772 and 11.10338786 meters\n",
    "SELECT ST_Distance(\n",
    "    ST_GeographyFromText('SRID=4326;POINT(' || -75.14144069 || ' ' || 39.96071159 || ')'),\n",
    "    ST_GeographyFromText('SRID=4326;POINT(' || (-75.14144069 + 0.0001) || ' ' || 39.96071159 || ')')\n",
    ") AS distance_in_meters_lng,\n",
    "ST_Distance(\n",
    "    ST_GeographyFromText('SRID=4326;POINT(' || -75.14144069 || ' ' || 39.96071159 || ')'),\n",
    "    ST_GeographyFromText('SRID=4326;POINT(' || (-75.14144069) || ' ' || 39.96071159  + 0.0001 || ')')\n",
    ") AS distance_in_meters_lat\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Run(BaseModel):\n",
    "    zip_filename: str\n",
    "    zip_filename_override_dict: dict[str, str] = {}\n",
    "\n",
    "    @property\n",
    "    def zip_filepath(self):\n",
    "        return os.path.join(DATA_DIR, self.zip_filename)\n",
    "\n",
    "    @property\n",
    "    def db_name(self):\n",
    "        # car_ped_stops_2024-03-16T20_22_24.zip -> 2014_03_16\n",
    "        return (\n",
    "            self.zip_filename.replace(\"car_ped_stops_\", \"\")\n",
    "            .split(\"T\")[0]\n",
    "            .replace(\"-\", \"_\")\n",
    "        )\n",
    "\n",
    "\n",
    "def get_q_end_from_q_start_str(q_start_str):\n",
    "    q_start = pd.to_datetime(q_start_str)\n",
    "    if q_start.month in [1, 2, 3]:\n",
    "        q_end = datetime.combine(date(q_start.year, 3, 31), datetime.max.time())\n",
    "    elif q_start.month in [4, 5, 6]:\n",
    "        q_end = datetime.combine(date(q_start.year, 6, 30), datetime.max.time())\n",
    "    elif q_start.month in [7, 8, 9]:\n",
    "        q_end = datetime.combine(date(q_start.year, 9, 30), datetime.max.time())\n",
    "    else:\n",
    "        q_end = datetime.combine(date(q_start.year, 12, 31), datetime.max.time())\n",
    "    return q_end\n",
    "\n",
    "\n",
    "MOST_RECENT_QUARTER_END_DT = get_q_end_from_q_start_str(MOST_RECENT_QUARTER_START_DT)\n",
    "\n",
    "\n",
    "def add_quarterly_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"quarter_dt_str\"] = df[\"quarter\"]\n",
    "    df[\"quarter_dt\"] = pd.to_datetime(df[\"quarter\"])\n",
    "    df[\"quarter\"] = (\n",
    "        df[\"quarter_dt\"].dt.year.astype(str)\n",
    "        + \"-Q\"\n",
    "        + df[\"quarter_dt\"].dt.quarter.astype(str)\n",
    "    )\n",
    "    df[\"quarter_date\"] = df[\"quarter_dt\"].dt.date\n",
    "    df[\"q_str\"] = \"Q\" + df[\"quarter_dt\"].dt.quarter.astype(str)\n",
    "    df[\"year\"] = df[\"quarter_dt\"].dt.year\n",
    "    return df\n",
    "\n",
    "\n",
    "# Used to get dtype dict\n",
    "def get_pandas_dtype_and_parse_dates():\n",
    "    response = requests.get(\n",
    "        \"https://phl.carto.com/api/v2/sql?q=select * from car_ped_stops limit 0\"\n",
    "    )\n",
    "    schema = response.json()[\"fields\"]\n",
    "\n",
    "    def convert_to_pandas_dtype(schema):\n",
    "        dtype_map = {\n",
    "            \"int4\": \"int32\",\n",
    "            \"int8\": \"int64\",\n",
    "            \"text\": \"str\",\n",
    "            \"numeric\": \"float\",\n",
    "            # Add more mappings as needed\n",
    "        }\n",
    "\n",
    "        parse_dates = []  # list to keep track of date columns\n",
    "        dtype_dict = {}  # dict to hold the resulting dtype mappings\n",
    "\n",
    "        for column, info in schema.items():\n",
    "            if info[\"type\"] in [\"geometry\", \"string\"]:\n",
    "                dtype_dict[column] = \"str\"\n",
    "            elif info[\"type\"] == \"number\":\n",
    "                dtype_dict[column] = dtype_map.get(\n",
    "                    info[\"pgtype\"], \"float\"\n",
    "                )  # Default to float if not specified\n",
    "            elif info[\"type\"] == \"date\":\n",
    "                parse_dates.append(\n",
    "                    column\n",
    "                )  # Add to parse_dates list for later use with pandas\n",
    "            else:\n",
    "                raise ValueError(column, info)\n",
    "        return dtype_dict, parse_dates\n",
    "\n",
    "    return convert_to_pandas_dtype(schema)\n",
    "\n",
    "\n",
    "dtype_dict = {\n",
    "    \"cartodb_id\": \"int64\",\n",
    "    \"the_geom\": \"str\",  # Special handling might be required for geometry\n",
    "    \"the_geom_webmercator\": \"str\",  # Special handling might be required for geometry\n",
    "    \"objectid\": \"int32\",\n",
    "    \"id\": \"int32\",\n",
    "    \"weekday\": \"str\",\n",
    "    \"location\": \"str\",\n",
    "    \"districtoccur\": \"str\",\n",
    "    \"psa\": \"str\",\n",
    "    \"stopcode\": \"int32\",\n",
    "    \"stoptype\": \"str\",\n",
    "    \"inside_or_outside\": \"str\",\n",
    "    \"gender\": \"str\",\n",
    "    \"race\": \"str\",\n",
    "    \"age\": \"float\",\n",
    "    \"individual_frisked\": \"float\",\n",
    "    \"individual_searched\": \"float\",\n",
    "    \"individual_arrested\": \"float\",\n",
    "    \"individual_contraband\": \"float\",\n",
    "    \"vehicle_frisked\": \"float\",\n",
    "    \"vehicle_searched\": \"float\",\n",
    "    \"vehicle_contraband\": \"float\",\n",
    "    \"vehicle_contraband_list\": \"str\",\n",
    "    \"individual_contraband_list\": \"str\",\n",
    "    \"mvc_code\": \"str\",\n",
    "    \"mvc_reason\": \"str\",\n",
    "    \"mvc_code_sec\": \"str\",\n",
    "    \"mvc_code_sec_reason\": \"str\",\n",
    "    \"point_x\": \"float64\",  # Adjusted to 'float64' for numeric\n",
    "    \"point_y\": \"float64\",  # Adjusted to 'float64' for numeric\n",
    "}\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "(\n",
    "    strftime('%Y', datetimeoccur_local) || '-' ||\n",
    "    CASE\n",
    "      WHEN strftime('%m', datetimeoccur_local) BETWEEN '01' AND '03' THEN '01'\n",
    "      WHEN strftime('%m', datetimeoccur_local) BETWEEN '04' AND '06' THEN '04'\n",
    "      WHEN strftime('%m', datetimeoccur_local) BETWEEN '07' AND '09' THEN '07'\n",
    "      WHEN strftime('%m', datetimeoccur_local) BETWEEN '10' AND '12' THEN '10'\n",
    "    END || '-01T00:00:00.000000Z'\n",
    ") AS quarter,\n",
    "CAST(strftime('%Y', datetimeoccur_local) as int) as year,\n",
    "--Replace Above with Postgres equivalents (using extract())\n",
    "districtoccur, \n",
    "psa,\n",
    "violation_category,\n",
    "race as \"Race\", \n",
    "gender as \"Gender\", \n",
    "age_range as \"Age Range\",\n",
    "count(*) as n_stopped, \n",
    "sum(n_people_in_car) as n_people_in_stopped_vehicles,\n",
    "sum(was_searched) as n_searched,\n",
    "sum(was_arrested) as n_arrested,\n",
    "sum(was_found_with_contraband) as n_contraband,\n",
    "sum(was_frisked) as n_frisked,\n",
    "sum(was_intruded) as n_intruded\n",
    "FROM (\n",
    "    SELECT \n",
    "    stop.*, driver.race, driver.age_range, driver.gender,datetimeoccur_local, n_people_in_car,\n",
    "    CASE\n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '1332%' AND mvc_code_clean LIKE '%A%' AND mvc_code_clean NOT LIKE '1332AI%') \n",
    "        THEN 'Display License Plate'\n",
    "        WHEN \n",
    "            (mvc_code_clean = '3111') OR\n",
    "            (mvc_code_clean LIKE '3111%' AND mvc_code_clean LIKE '%A%')\n",
    "        THEN 'Failure to Obey Traffic Sign/Light'   \n",
    "        WHEN\n",
    "            (mvc_code_clean LIKE '330%') OR\n",
    "            (mvc_code_clean LIKE '3311%' AND mvc_code_clean LIKE '%A%') OR\n",
    "            (mvc_code_clean LIKE '3313%') OR\n",
    "            (mvc_code_clean LIKE '3315%') OR\n",
    "            (mvc_code_clean LIKE '3703%')\n",
    "        THEN 'Improper Pass, Lane, One Way'  \n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '3331%') OR\n",
    "            (mvc_code_clean LIKE '3332%') OR\n",
    "            (mvc_code_clean LIKE '3334%' AND mvc_code_clean LIKE '%A%') OR\n",
    "            (mvc_code_clean LIKE '3334%' AND mvc_code_clean LIKE '%B%') OR\n",
    "            (mvc_code_clean LIKE '3335%') OR\n",
    "            (mvc_code_clean LIKE '3336%') \n",
    "        THEN 'Improper Turn/Signal'\n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '4703%') OR\n",
    "            (mvc_code_clean LIKE '4706%' AND mvc_code_clean LIKE '%C%')\n",
    "        THEN 'Inspection/Emission Sticker'   \n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '4301%') OR\n",
    "            (mvc_code_clean LIKE '4302%') OR\n",
    "            (mvc_code_clean LIKE '4303%') OR\n",
    "            (mvc_code_clean = '4306') \n",
    "        THEN 'Lights'\n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '3112%') OR\n",
    "            (mvc_code_clean LIKE '3321%') OR\n",
    "            (mvc_code_clean LIKE '3322%') OR\n",
    "            (mvc_code_clean LIKE '3323%') OR\n",
    "            (mvc_code_clean LIKE '3324%') OR\n",
    "            (mvc_code_clean LIKE '3325%') OR\n",
    "            (mvc_code_clean LIKE '3342%' AND mvc_code_clean LIKE '%A%') OR\n",
    "            (mvc_code_clean LIKE '3345%' AND mvc_code_clean LIKE '%A%') OR\n",
    "            (mvc_code_clean LIKE '3542%') OR\n",
    "            (mvc_code_clean LIKE '3710%')\n",
    "        THEN 'Red Light/Stop Sign/Yield'\n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '1301%' and mvc_code_clean LIKE '%A%') \n",
    "        THEN 'Registration'\n",
    "        WHEN (mvc_code_clean LIKE '3361%') OR\n",
    "             (mvc_code_clean LIKE '3362%') OR\n",
    "             (mvc_code_clean LIKE '3363%') OR\n",
    "             (mvc_code_clean LIKE '3365%') OR\n",
    "             (mvc_code_clean LIKE '3367%') OR\n",
    "             (mvc_code_clean LIKE '3714%') OR\n",
    "             (mvc_code_clean LIKE '3736%') \n",
    "        THEN 'Speeding/Reckless/Careless Driving'\n",
    "        WHEN\n",
    "            (mvc_code_clean LIKE '4524%' AND mvc_code_clean NOT LIKE '%A%')\n",
    "        THEN 'Tint'\n",
    "        WHEN \n",
    "            (mvc_code_clean LIKE '4524%' AND mvc_code_clean LIKE '%A%')\n",
    "        THEN 'Windshield Obstruction'\n",
    "        WHEN mvc_code_clean is not null THEN 'Other'\n",
    "        ELSE 'None'\n",
    "    END AS violation_category\n",
    "    FROM (\n",
    "            SELECT car_ped_stops.datetimeoccur as datetimeoccur_d,location as location_d,gender, \n",
    "            n_people_in_car,\n",
    "            CASE\n",
    "                WHEN race = 'Black - Latino' THEN 'Latino'\n",
    "                WHEN race = 'White - Latino' THEN 'Latino'\n",
    "                WHEN race = 'White - Non-Latino' THEN 'White'\n",
    "                WHEN race = 'Black - Non-Latino' THEN 'Black'\n",
    "                WHEN race = 'Asian' THEN 'Asian'\n",
    "                WHEN race = 'American Indian' THEN 'All Other Races'\n",
    "                WHEN race = 'Unknown' THEN 'All Other Races'\n",
    "                ELSE race\n",
    "            END as race,\n",
    "            CASE\n",
    "                WHEN age <25 THEN 'Under 25'\n",
    "                WHEN age <35 THEN '25-34'\n",
    "                WHEN age <45 THEN '35-44'\n",
    "                WHEN age <55 THEN '45-54'\n",
    "                WHEN age < 65 THEN '55-64'\n",
    "                ELSE '65+'\n",
    "            END as age_range\n",
    "            FROM (\n",
    "                SELECT location as driverl, min(id) as id, count(*) as n_people_in_car\n",
    "                FROM car_ped_stops\n",
    "                where stoptype='vehicle'\n",
    "                GROUP by datetimeoccur, location\n",
    "            ) inner_driver\n",
    "            LEFT JOIN car_ped_stops\n",
    "            ON inner_driver.id = car_ped_stops.id\n",
    "        ) driver\n",
    "    LEFT JOIN (\n",
    "        SELECT datetimeoccur as datetimeoccur_utc, datetimeoccur_local, \n",
    "        location, min(districtoccur) as districtoccur, min(psa) as psa,\n",
    "        CASE \n",
    "            WHEN sum(individual_searched) > 0 or sum(vehicle_searched) > 0 \n",
    "            THEN 1 ELSE 0 \n",
    "        END as was_searched,\n",
    "        CASE \n",
    "            WHEN sum(individual_arrested) > 0 \n",
    "            THEN 1 ELSE 0 \n",
    "        END as was_arrested,\n",
    "        CASE \n",
    "            WHEN sum(individual_contraband) > 0 or sum(vehicle_contraband) > 0 \n",
    "            THEN 1 ELSE 0 \n",
    "        END as was_found_with_contraband,\n",
    "        CASE\n",
    "            WHEN sum(individual_frisked) > 0 or sum(vehicle_frisked) > 0 \n",
    "            THEN 1 ELSE 0 \n",
    "        END as was_frisked,\n",
    "        CASE\n",
    "            WHEN\n",
    "                sum(individual_frisked) > 0 or sum(vehicle_frisked) > 0\n",
    "                or sum(individual_searched) > 0 or sum(vehicle_searched) > 0\n",
    "            THEN 1 ELSE 0\n",
    "        END as was_intruded,\n",
    "        UPPER(\n",
    "            REPLACE(\n",
    "                REPLACE(\n",
    "                    REPLACE(\n",
    "                        REPLACE(\n",
    "                            REPLACE(max(mvc_code),'i','1'),\n",
    "                        '(', ''),\n",
    "                    ')', ''),\n",
    "                '-',''),\n",
    "            ' ','')\n",
    "        ) as mvc_code_clean\n",
    "        FROM car_ped_stops\n",
    "        WHERE stoptype='vehicle'\n",
    "        GROUP by datetimeoccur_utc, location\n",
    "    ) stop\n",
    "    ON stop.datetimeoccur_utc=driver.datetimeoccur_d\n",
    "    AND stop.location=driver.location_d\n",
    ") query\n",
    "WHERE datetimeoccur_local  <= '{MOST_RECENT_QUARTER_END_DT}'\n",
    "GROUP by districtoccur,psa, quarter,race, gender, age_range, violation_category\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_df_quarterly_reason_from_zipfiles(run: Run):\n",
    "    def get_df_from_zipped_csv(zip_filename, csv_filename):\n",
    "        with open(zip_filename, \"rb\") as file:\n",
    "            zip_data = file.read()\n",
    "            with zipfile.ZipFile(io.BytesIO(zip_data), \"r\") as z:\n",
    "                csv_files = sorted([f for f in z.namelist() if f.endswith(\".csv\")])\n",
    "                for available_filename in csv_files:\n",
    "                    # in case the zip structure changed\n",
    "                    if os.path.basename(available_filename) == os.path.basename(\n",
    "                        csv_filename\n",
    "                    ):\n",
    "                        with z.open(available_filename) as csv_file:\n",
    "                            return pd.read_csv(\n",
    "                                csv_file,\n",
    "                                dtype=dtype_dict,\n",
    "                                parse_dates=[\"datetimeoccur\"],\n",
    "                            )\n",
    "\n",
    "    with open(run.zip_filepath, \"rb\") as file:\n",
    "        zip_data = file.read()\n",
    "    dfs = []\n",
    "    print(run.zip_filename)\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_data), \"r\") as z:\n",
    "        csv_files = sorted([f for f in z.namelist() if f.endswith(\".csv\")])\n",
    "        pbar = tqdm(total=len(csv_files))\n",
    "        for filename in csv_files:\n",
    "            filename_raw = os.path.basename(filename)\n",
    "            zip_filename_override = run.zip_filename_override_dict.get(\n",
    "                os.path.basename(filename)\n",
    "            )\n",
    "            if zip_filename_override:\n",
    "                print(f\"Overriding for {zip_filename_override}: {filename_raw}\")\n",
    "                this_df = get_df_from_zipped_csv(zip_filename_override, filename)\n",
    "            else:\n",
    "                with z.open(filename) as csv_file:\n",
    "                    this_df = pd.read_csv(\n",
    "                        csv_file, dtype=dtype_dict, parse_dates=[\"datetimeoccur\"]\n",
    "                    )\n",
    "            this_df[\"datetimeoccur_local\"] = (\n",
    "                this_df[\"datetimeoccur\"]\n",
    "                .dt.tz_convert(\"America/New_York\")\n",
    "                .dt.tz_localize(None)\n",
    "            )\n",
    "            this_df = this_df.sort_values(\"id\").reset_index(drop=True)\n",
    "            # Dramatically improves speed for some reason.\n",
    "            this_df[\"id\"] = this_df.index\n",
    "            pbar.set_description(f\"{filename_raw} has {len(this_df)} rows\")\n",
    "            con = sqlite3.connect(\":memory:\")\n",
    "            this_df.to_sql(\"car_ped_stops\", if_exists=\"replace\", con=con)\n",
    "            df_this_result = pd.read_sql(query, con=con)\n",
    "            dfs.append(df_this_result)\n",
    "            pbar.update()\n",
    "\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def make_request(sql: str):\n",
    "    with httpx.Client(timeout=90) as client:\n",
    "        response = client.post(\"https://phl.carto.com/api/v2/sql\", data={\"q\": sql})\n",
    "        try:\n",
    "            json = response.json()\n",
    "            breakpoint()\n",
    "        except Exception:\n",
    "            raise ValueError(response.text)\n",
    "        if \"rows\" not in json:\n",
    "            raise ValueError(f\"{sql}\\n\\n{json}\")\n",
    "        return json\n",
    "\n",
    "\n",
    "def get_hin_random_sample_from_odp(dist_from_hin_threshold=DIST_FROM_HIN_THRESHOLD):\n",
    "    # Static so only needed to download once\n",
    "    \"\"\"\n",
    "    response = requests.get(\n",
    "        \"https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+high_injury_network_2020&filename=high_injury_network_2020&format=geojson&skipfields=cartodb_id\"\n",
    "    )\n",
    "    geojson = response.json()\n",
    "    json.dump(geojson, open(f\"{DATA_DIR}/hin.geojson\", \"w\"))\n",
    "    \"\"\"\n",
    "\n",
    "    response_hin = make_request(\n",
    "        f\"\"\"\n",
    "        SELECT stops.point_x, stops.point_y, ST_DISTANCE(stops.the_geom, hin.the_geom) as distance_from_hin,\n",
    "        hin.street_name is not null as on_hin FROM\n",
    "        (\n",
    "            SELECT * FROM car_ped_stops \n",
    "            where point_y < 42 \n",
    "            and extract(year from datetimeoccur) = '{MOST_RECENT_COMPLETED_YEAR}'\n",
    "            order by random() limit 1000\n",
    "        ) stops\n",
    "        LEFT JOIN high_injury_network_2020 hin\n",
    "        ON ST_DWithin(stops.the_geom, hin.the_geom, {DIST_FROM_HIN_THRESHOLD})\n",
    "        \"\"\"\n",
    "    )\n",
    "    return pd.DataFrame(response_hin[\"rows\"])\n",
    "\n",
    "\n",
    "def get_hin_by_quarter_from_odp():\n",
    "    df_hins = []\n",
    "    quarters = make_request(\n",
    "        \"\"\"\n",
    "    SELECT \n",
    "       distinct date_trunc('quarter',datetimeoccur AT TIME ZONE 'America/New_York') as quarter\n",
    "       from car_ped_stops order by quarter\n",
    "    \"\"\"\n",
    "    )\n",
    "    for quarter_row in tqdm(quarters[\"rows\"]):\n",
    "        quarter = quarter_row[\"quarter\"]\n",
    "\n",
    "        response_hin_by_quarter = make_request(\n",
    "            f\"\"\"\n",
    "        SELECT \n",
    "            districtoccur, psa, date_trunc('quarter',datetimeoccur AT TIME ZONE 'America/New_York') as quarter,\n",
    "            sum(CASE WHEN hin.street_name is not null \n",
    "            AND st_y(car_ped_stops.the_geom)<42 and car_ped_stops.the_geom is not null\n",
    "            THEN 1 ELSE 0 END\n",
    "            ) as n_stopped_locatable_on_hin,\n",
    "            CAST(sum(\n",
    "                case when st_y(car_ped_stops.the_geom)<42 and car_ped_stops.the_geom is not null then 1 else 0 end\n",
    "            ) as float) as n_stopped_locatable\n",
    "            FROM car_ped_stops\n",
    "            LEFT JOIN high_injury_network_2020 hin\n",
    "            ON ST_DWithin(car_ped_stops.the_geom, hin.the_geom, {DIST_FROM_HIN_THRESHOLD})\n",
    "            WHERE datetimeoccur AT TIME ZONE 'America/New_York'  <= '{MOST_RECENT_QUARTER_END_DT}'\n",
    "            AND date_trunc('quarter',datetimeoccur AT TIME ZONE 'America/New_York') = '{quarter}'\n",
    "            GROUP BY districtoccur,psa, date_trunc('quarter',datetimeoccur AT TIME ZONE 'America/New_York')\n",
    "\n",
    "        \"\"\"\n",
    "        )\n",
    "        df_hin_quarter = pd.DataFrame(response_hin_by_quarter[\"rows\"])\n",
    "        df_hins.append(df_hin_quarter)\n",
    "    df_hin_by_quarter = pd.concat(df_hins)\n",
    "    df_hin_by_quarter = add_quarterly_columns(df_hin_by_quarter)\n",
    "    return df_hin_by_quarter\n",
    "\n",
    "def get_shootings_from_odp():\n",
    "    query = \"\"\"\n",
    "        select\n",
    "        count(*) as n_shootings,\n",
    "        sum(case WHEN inside='0' THEN 1 else 0 END) as n_outside,\n",
    "        dist as districtoccur,\n",
    "        date_trunc('quarter',date_) as quarter\n",
    "        from shootings\n",
    "        group by date_trunc('quarter',date_), dist\n",
    "        order by quarter,dist\n",
    "    \"\"\"\n",
    "    query = re.sub(r\"\\s+\", \" \", query).strip()\n",
    "    response = requests.get(\"https://phl.carto.com/api/v2/sql\", params={\"q\": query})\n",
    "    df_shootings = pd.DataFrame(response.json()[\"rows\"])\n",
    "    df_shootings[\"districtoccur\"] = (\n",
    "        df_shootings[\"districtoccur\"].astype(str).str.zfill(2)\n",
    "    )\n",
    "    df_shootings = add_quarterly_columns(df_shootings)\n",
    "    return df_shootings\n",
    "\n",
    "\n",
    "\n",
    "def make_db(run:Run):\n",
    "    sqlite_file = os.path.join(DATA_DIR, f\"open_data_philly_{run.db_name}.db\")\n",
    "    df_quarterly_reason = get_df_quarterly_reason_from_zipfiles(run)\n",
    "    df_quarterly = (\n",
    "        df_quarterly_reason.drop(\"violation_category\", axis=1)\n",
    "        .groupby(\n",
    "            [\n",
    "                \"districtoccur\",\n",
    "                \"psa\",\n",
    "                \"quarter\",\n",
    "                \"Race\",\n",
    "                \"Gender\",\n",
    "                \"Age Range\",\n",
    "            ]\n",
    "        )\n",
    "        .sum()\n",
    "    ).reset_index()\n",
    "    df_quarterly = add_quarterly_columns(df_quarterly)\n",
    "    df_quarterly.to_sql(\n",
    "        \"car_ped_stops_quarterly\",\n",
    "        con=sqlite3.connect(sqlite_file),\n",
    "        index=False,\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "    df_quarterly_reason = add_quarterly_columns(df_quarterly_reason)\n",
    "    df_quarterly_reason.to_sql(\n",
    "        \"car_ped_stops_quarterly_reason\",\n",
    "        con=sqlite3.connect(sqlite_file),\n",
    "        index=False,\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "    print(\"Pulling from HIN\")\n",
    "    df_hin = get_hin_random_sample_from_odp()\n",
    "    df_hin.to_sql(\n",
    "        \"car_ped_stops_hin_random_sample\",\n",
    "        if_exists=\"replace\",\n",
    "        con=sqlite3.connect(sqlite_file),\n",
    "        index=False,\n",
    "    )\n",
    "    df_hin_by_quarter = get_hin_by_quarter_from_odp()\n",
    "    df_hin_by_quarter = add_quarterly_columns(df_hin_by_quarter)\n",
    "    df_hin_by_quarter.to_sql(\n",
    "        'car_ped_stops_hin_pct',\n",
    "        if_exists='replace', \n",
    "        con=sqlite3.connect(sqlite_file), \n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(\"Get Shooting data\")\n",
    "    df_shootings = get_shootings_from_odp()\n",
    "    df_shootings.to_sql(\n",
    "        \"shootings\",\n",
    "        con=sqlite3.connect(sqlite_file),\n",
    "        index=False,\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "    print(f\"Complete and saved to {sqlite_file}\")\n",
    "\n",
    "run = Run(zip_filename=ZIP_FILENAME)\n",
    "make_db(run=run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
